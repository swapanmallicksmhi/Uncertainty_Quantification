#!/bin/sh
#-------------------------------
#SBATCH --job-name=DDPM_TRAIN
#SBATCH --output=log.out
#SBATCH --error=log.out
#SBATCH --qos=ng
#SBATCH --nodes=1
#SBATCH --mem=60GB
#SBATCH --gpus=4
#SBATCH --time=36:00:00
#-------------------------------

set -evx
module load conda
conda activate ddenv_v2

# CUDA-aware MPI & fragmentation mitigation
export OMPI_MCA_opal_cuda_support=true
export OMPI_MCA_pml=ucx
export UCX_MEMTYPE_CACHE=n
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

VAR="t2m"
INPUT="${SCRATCH}/DDPM/DATA/INPUT_TRAIN/${VAR}"
OUTPUT="${SCRATCH}/DDPM/MODEL/${VAR}"

# Lowered batch + microbatch + enable fp16
MODEL_FLAGS="--image_size 256 --num_channels 64"   # reduce model size if needed
TOTALSTEP="--steps 20000"
TRAIN_FLAGS="--lr 1e-4 --batch_size 8 --microbatch 4 --use_fp16 True"

mkdir -p $OUTPUT

# Launch
srun --mpi=pmi2 torchrun --nproc_per_node=4 Train_Main.py \
    --data_dir $INPUT --TRAIN_OUT $OUTPUT \
      $MODEL_FLAGS $TOTALSTEP $TRAIN_FLAGS
